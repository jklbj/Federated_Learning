{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages',\n",
       " '/home/mnetlab/anaconda3/envs/pp_fl/lib/python36.zip',\n",
       " '/home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6',\n",
       " '/home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/mnetlab/.local/lib/python3.6/site-packages',\n",
       " '/home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages',\n",
       " '/home/mnetlab/.local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/mnetlab/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Modified fedavg for our input\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Other import\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from data.preprocessing import preprocessing_for_training, separate_and_preprocess_for_simple_fed, evaluate_with_new_model\n",
    "from data.read_data import read_data, read_setting\n",
    "from data.data_utils import load_cifar10_data, train_test_label_to_categorical\n",
    "from model.model import init_model, init_load_model, record_history, training_once, print_result_for_fed\n",
    "from model.operation import broadcast_to_device, caculate_delta, aggregate_add, aggregate_division_return \n",
    "from config.environment import gpu_decision, zmq_bind, zmq_connect\n",
    "\n",
    "from math import floor\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import zmq\n",
    "\n",
    "# for gpu memory\n",
    "import xml.etree.ElementTree\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mnetlab/Jeff/config/environment.py:22: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mnetlab/Jeff/config/environment.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "\u001b[1mRound: 0\n",
      "\u001b[0mDevice: 0 model_0\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 1 model_1\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 2 model_2\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 3 model_3\n",
      "response: b'ok'\n",
      "Received: b'finish'\n",
      "WARNING:tensorflow:From /home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mnetlab/anaconda3/envs/pp_fl/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnetlab/Jeff/model/operation.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  model_0.layers[layer].get_weights()))\n",
      "/home/mnetlab/Jeff/model/operation.py:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.divide(model_0.layers[layer].get_weights(), num_device)\n",
      "/home/mnetlab/Jeff/model/operation.py:61: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  model_m.layers[layer].set_weights(np.add(model_m.layers[layer].get_weights(), model_0_result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 148us/sample - loss: 2.6534 - acc: 0.1000\n",
      "\n",
      "Round 0 \n",
      "Accuracy: 0.1, Loss: 2.6534363338470457\n",
      "\n",
      "\u001b[1mRound: 1\n",
      "\u001b[0mDevice: 0 model_0\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 1 model_1\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 2 model_2\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 3 model_3\n",
      "response: b'ok'\n",
      "Received: b'finish'\n",
      "10000/10000 [==============================] - 1s 54us/sample - loss: 2.2718 - acc: 0.1166\n",
      "\n",
      "Round 1 \n",
      "Accuracy: 0.1166, Loss: 2.2717701152801513\n",
      "\n",
      "\u001b[1mRound: 2\n",
      "\u001b[0mDevice: 0 model_0\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 1 model_1\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 2 model_2\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 3 model_3\n",
      "response: b'ok'\n",
      "Received: b'finish'\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 1.0672 - acc: 0.6896\n",
      "\n",
      "Round 2 \n",
      "Accuracy: 0.6896, Loss: 1.0671874478340149\n",
      "\n",
      "\u001b[1mRound: 3\n",
      "\u001b[0mDevice: 0 model_0\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 1 model_1\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 2 model_2\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 3 model_3\n",
      "response: b'ok'\n",
      "Received: b'finish'\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.9426 - acc: 0.7110\n",
      "\n",
      "Round 3 \n",
      "Accuracy: 0.711, Loss: 0.9425821039199829\n",
      "\n",
      "\u001b[1mRound: 4\n",
      "\u001b[0mDevice: 0 model_0\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 1 model_1\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 2 model_2\n",
      "response: b'ok'\n",
      "\u001b[0mDevice: 3 model_3\n",
      "response: b'ok'\n"
     ]
    }
   ],
   "source": [
    "# Connect zmq socket port\n",
    "socket = zmq_connect()\n",
    "# Decide gpu\n",
    "gpu_decision()\n",
    "# Read detailed settings from json file\n",
    "detailed_setting = read_setting()\n",
    "# Load CIFAR-10 data\n",
    "train_images, train_labels, test_images, test_labels = load_cifar10_data()\n",
    "# Transfer train and test label to be categorical\n",
    "train_label, test_label = train_test_label_to_categorical(train_labels, test_labels)\n",
    "\n",
    "training_info = detailed_setting[\"training_info\"]\n",
    "\n",
    "# Define our model\n",
    "is_master = True \n",
    "model_m, history_total = init_model(is_master)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(training_info[\"num_round\"]):\n",
    "    print(\"\\n\" + \"\\033[1m\" + \"Round: \" + str(_))\n",
    "    start_training = time.time()\n",
    "    \n",
    "    for device in range(training_info[\"num_device\"]):\n",
    "        print(\"\\033[0m\" + \"Device:\", device, \"model_\" + str(device))\n",
    "        message = \"{}:{}\".format(_, device)\n",
    "        socket.send(bytes(message, encoding = \"utf8\"))\n",
    "        response = socket.recv()\n",
    "        print(\"response: %s\" % response)  \n",
    "        \n",
    "    while True:\n",
    "        socket.send(b\"aggregate\")\n",
    "        message = socket.recv()\n",
    "        print(\"Received: %s\" % message)\n",
    "        if(message == b\"finish\"): break\n",
    "            \n",
    "    start_load_w = time.time()\n",
    "    training_time = start_load_w - start_training\n",
    "            \n",
    "    is_master = False\n",
    "    if(_ == 0):\n",
    "        # Define and initialize an estimator model\n",
    "        for device in range(training_info[\"num_device\"]):\n",
    "            globals()['model_{}'.format(device)] = tf.keras.models.load_model('parallel/model_{}.h5'.format(device))\n",
    "    else:\n",
    "        for device in range(training_info[\"num_device\"]):\n",
    "            globals()['model_{}'.format(device)].load_weights('parallel/model_{}.h5'.format(device))                                 \n",
    "        \n",
    "    loadweight_time = time.time() - start_load_w\n",
    "    \n",
    "    # Aggregate all delta weight on device 0 (Addition)\n",
    "    for device in range(1, training_info[\"num_device\"]):\n",
    "        aggregate_add(globals()['model_{}'.format(device)], model_0)\n",
    "\n",
    "    # Aggregate all delta weight on device 0 (Division) and return total delta weight to center device\n",
    "    aggregate_division_return(model_0, model_m, training_info[\"num_device\"])\n",
    "\n",
    "    # Evaluate with new weight\n",
    "    history_temp = evaluate_with_new_model(_, training_info, model_m, test_images, test_label)\n",
    "    model_m.save('parallel/model_m.h5')\n",
    "\n",
    "    # Record each round accuracy\n",
    "    record_history(history_temp, history_total)\n",
    "    \n",
    "    round_time = time.time() - start_training\n",
    "\n",
    "print(\"training time: \", (time.time() - start))\n",
    "print_result_for_fed(history_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp_fl",
   "language": "python",
   "name": "pp_fl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
